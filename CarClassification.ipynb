{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Classification\n",
    "This is a car classificator build using pretrained VGG16 on ImageNet data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Setup and authenticate the use of AWS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker' # custom bucket name.\n",
    "prefix = 'car-Detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version=\"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Create folders to store the data and annotation files\n",
    "mkdir car-generated car-train car-train_annotation car-validation car-validation_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "The model has been trained on [Cars Dataset from Stanford](http://ai.stanford.edu/~jkrause/cars/car_dataset.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "\n",
    "download('http://imagenet.stanford.edu/internal/car196/cars_train.tgz')\n",
    "download('https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "tar -xzf car_devkit.tgz\n",
    "tar -xzf cars_train.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data\n",
    "The Amazon SageMaker Object Detection algorithm expects lables to be indexed from 0. It also expects lables to be unique, successive and not skip any integers. For instance, if there are ten classes, the algorithm expects and the labels only be in the set [0,1,2,3,4,5,6,7,8,9].\n",
    "\n",
    "In the car validation set, the labels do not satistify this requirement. Some indices are skipped and the labels start from 1. We therefore need a mapper that will convert this index system to our requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "        \n",
    "def readClasses(matFile):   \n",
    "    content = sio.loadmat(matFile)\n",
    "    classes = [(_[0]) for _ in content['class_names'][0]]\n",
    "    return classes    \n",
    "\n",
    "def readAnnos(matFile):   \n",
    "    content = sio.loadmat(matFile)\n",
    "    return content['annotations'][0]\n",
    "\n",
    "def get_class_mapper():\n",
    "    original_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, \n",
    "                     19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, \n",
    "                     36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, \n",
    "                     54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, \n",
    "                     72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, \n",
    "                     90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, \n",
    "                     107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, \n",
    "                     122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, \n",
    "                     137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, \n",
    "                     152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, \n",
    "                     167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, \n",
    "                     182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196]\n",
    "    iter_counter = 0\n",
    "    CLASS = {}\n",
    "    for orig in original_list:\n",
    "        CLASS[orig] = iter_counter\n",
    "        iter_counter += 1\n",
    "    return CLASS\n",
    "\n",
    "\n",
    "fix_index_mapping = get_mapper_fn(get_class_mapper())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapper_fn(map):  \n",
    "    def mapper(in_category):\n",
    "        return map[in_category]\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# get images\n",
    "images=os.listdir('cars_train')\n",
    "for fichier in images[:]: # filelist[:] makes a copy of filelist.\n",
    "    if not(fichier.endswith(\".jpg\")):\n",
    "        images.remove(fichier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "import scipy.io as sio\n",
    "\n",
    "categories = readClasses(\"devkit/cars_meta.mat\")\n",
    "annotations = readAnnos(\"devkit/cars_train_annos.mat\")\n",
    "\n",
    "for img in images :\n",
    "    shape = imread('cars_train/{}'.format(img)).shape\n",
    "    jsonFile = img.split('.')[0]+'.json'\n",
    "    \n",
    "    line = {}\n",
    "    line['file'] = img\n",
    "    line['image_size'] = [{\n",
    "        'width':int(shape[1]),\n",
    "        'height':int(shape[0]),\n",
    "        'depth':3\n",
    "    }]\n",
    "     \n",
    "    line['annotations'] = []\n",
    "    line['categories'] = [] \n",
    "    #print(annotations)\n",
    "    for anno in annotations:\n",
    "         if(anno[5][0]==img):\n",
    "            #print(anno) \n",
    "            line['annotations'].append({\n",
    "                    'class_id':int(fix_index_mapping(anno[4][0][0])),\n",
    "                    'top':int(anno[1][0][0]),\n",
    "                    'left':int(anno[0][0][0]),\n",
    "                    'width':abs(int(anno[2][0][0])- int(anno[0][0][0])),\n",
    "                    'height':abs(int(anno[3][0][0]) -int(anno[1][0][0])),\n",
    "                })\n",
    "            class_name = ''\n",
    "            for ind,cat in enumerate(categories, start=1):\n",
    "                if int(anno[4][0][0]) == ind:\n",
    "                    class_name = str(cat)\n",
    "            assert class_name is not ''\n",
    "            line['categories'].append({\n",
    "                'class_id':int(anno[4][0][0]),\n",
    "                'name':class_name\n",
    "            })\n",
    "   \n",
    "    if line['annotations']:\n",
    "        with open(os.path.join('car-generated', jsonFile),'w') as p:\n",
    "            json.dump(line,p)      \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsons = os.listdir('car-generated')\n",
    "\n",
    "print ('There are {} images have annotation files.'.format(len(jsons)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "train_jsons = jsons[:6516]\n",
    "val_jsons = jsons[6516:]\n",
    " \n",
    "#Moving training files to the training folders\n",
    "for i in train_jsons:\n",
    "    image_file = './cars_train/'+i.split('.')[0]+'.jpg'\n",
    "    if  os.path.exists(image_file):\n",
    "        shutil.move(image_file, './car-train/')\n",
    "        shutil.move('./car-generated/'+i, './car-train_annotation/')\n",
    "\n",
    "#Moving validation files to the validation folders\n",
    "for i in val_jsons:\n",
    "    image_file = './cars_train/'+i.split('.')[0]+'.jpg'\n",
    "    if  os.path.exists(image_file):\n",
    "        shutil.move(image_file, './car-validation/')\n",
    "        shutil.move('./car-generated/'+i, './car-validation_annotation/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + '/car-train'\n",
    "validation_channel = prefix + '/car-validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'\n",
    "\n",
    "sess.upload_data(path='car-train', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='car-validation', bucket=bucket, key_prefix=validation_channel)\n",
    "sess.upload_data(path='car-train_annotation', bucket=bucket, key_prefix=train_annotation_channel)\n",
    "sess.upload_data(path='car-validation_annotation', bucket=bucket, key_prefix=validation_annotation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p2.8xlarge',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode = 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model.set_hyperparameters(base_network='vgg-16',\n",
    "                             use_pretrained_model=1,\n",
    "                             num_classes=196,\n",
    "                             mini_batch_size=16,\n",
    "                             epochs=10,\n",
    "                             learning_rate=0.001,\n",
    "                             lr_scheduler_step='10',\n",
    "                             lr_scheduler_factor=0.1,\n",
    "                             optimizer='sgd',\n",
    "                             momentum=0.9,\n",
    "                             weight_decay=0.0005,\n",
    "                             overlap_threshold=0.5,\n",
    "                             nms_threshold=0.45,\n",
    "                             image_shape=512,\n",
    "                             label_width=600,\n",
    "                             num_training_samples=6516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "train_annotation = sagemaker.session.s3_input(s3_train_annotation, distribution='FullyReplicated', \n",
    "                             content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_annotation = sagemaker.session.s3_input(s3_validation_annotation, distribution='FullyReplicated', \n",
    "                             content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data, \n",
    "                 'train_annotation': train_annotation, 'validation_annotation':validation_annotation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting\n",
    "Once the training is done, we can deploy the trained model as an Amazon SageMaker real-time hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector = od_model.deploy(initial_instance_count = 1,\n",
    "                                 instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Now that the trained model is deployed at an endpoint, we can use this endpoint for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O car.jpg https://afox.mobi/test/11111.jpg\n",
    "file_name = 'car.jpg'\n",
    "\n",
    "with open(file_name, 'rb') as image:\n",
    "    f = image.read()\n",
    "    b = bytearray(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "object_detector.content_type = 'image/jpeg'\n",
    "detections = json.loads(results)\n",
    "print (detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS have provided additional script to easily visualize the detection outputs. You can visulize the high-confidence preditions with bounding box by filtering out low-confidence detections using the script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):    \n",
    "        import random\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "\n",
    "        img=mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        colors = dict()\n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            cls_id = int(klass)\n",
    "            if cls_id not in colors:\n",
    "                colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "            xmin = int(x0 * width)\n",
    "            ymin = int(y0 * height)\n",
    "            xmax = int(x1 * width)\n",
    "            ymax = int(y1 * height)\n",
    "            rect = plt.Rectangle((xmin, ymin), xmax - xmin,\n",
    "                                 ymax - ymin, fill=False,\n",
    "                                 edgecolor=colors[cls_id],\n",
    "                                 linewidth=3.5)\n",
    "            plt.gca().add_patch(rect)\n",
    "            class_name = str(cls_id)\n",
    "            if classes and len(classes) > cls_id:\n",
    "                class_name = classes[cls_id]\n",
    "                print(class_name)\n",
    "            plt.gca().text(xmin, ymin - 2,\n",
    "                            '{:s} {:.3f}'.format(class_name, score),\n",
    "                            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                    fontsize=12, color='white')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.1\n",
    "\n",
    "visualize_detection(\"car.jpg\", detections['prediction'], categories, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint\n",
    "You can to remove the deployed endpoint by using script below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(object_detector.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
